{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Notebook for new gene programs identification in Cancer epithelial cells with *expimap*\n",
        "**Developed by:** Anna Maguza  \n",
        "**Institute of Computational Biology - Computational Health Centre - Helmholtz Munich**  \n",
        "**31st May 2023**"
      ],
      "metadata": {
        "id": "0zgcq7okeDCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import packages"
      ],
      "metadata": {
        "id": "Yp25MhiGexN_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frg8jyEXeAxN",
        "outputId": "68f7329a-e417-47ed-db54-3956fc3e7d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scarches\n",
            "  Downloading scArches-0.5.9-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scvi-tools\n",
            "  Downloading scvi_tools-0.20.3-py3-none-any.whl (330 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scib\n",
            "  Downloading scib-1.1.3-1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scib_metrics\n",
            "  Downloading scib_metrics-0.3.3-py3-none-any.whl (35 kB)\n",
            "Collecting scvi_colab\n",
            "  Downloading scvi_colab-0.12.0-py3-none-any.whl (4.2 kB)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scanpy>=1.6.0 (from scarches)\n",
            "  Downloading scanpy-1.9.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anndata>=0.7.4 (from scarches)\n",
            "  Downloading anndata-0.9.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scHPL>=1.0.0 (from scarches)\n",
            "  Downloading scHPL-1.0.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from scarches) (3.8.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from scarches) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.10/dist-packages (from scarches) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from scarches) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from scarches) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from scarches) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from scarches) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.10/dist-packages (from scarches) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from scarches) (2.27.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from scarches) (4.6.6)\n",
            "Collecting leidenalg (from scarches)\n",
            "  Downloading leidenalg-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting muon (from scarches)\n",
            "  Downloading muon-0.1.3-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.5/291.5 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chex in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.1.7)\n",
            "Collecting docrep>=0.3.2 (from scvi-tools)\n",
            "  Downloading docrep-0.3.2.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.6.9)\n",
            "Requirement already satisfied: jax>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.4.10)\n",
            "Requirement already satisfied: jaxlib>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.4.10+cuda11.cudnn86)\n",
            "Collecting ml-collections>=0.1.1 (from scvi-tools)\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mudata>=0.1.2 (from scvi-tools)\n",
            "  Downloading mudata-0.2.2-py3-none-any.whl (23 kB)\n",
            "Collecting numpyro (from scvi-tools)\n",
            "  Downloading numpyro-0.12.0-py3-none-any.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.6/304.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (3.0.10)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.1.5)\n",
            "Collecting pyro-ppl>=1.6.0 (from scvi-tools)\n",
            "  Downloading pyro_ppl-1.8.5-py3-none-any.whl (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.5/732.5 kB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning<1.10.0,>=1.9.0 (from scvi-tools)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (13.3.4)\n",
            "Collecting torchmetrics>=0.11.0 (from scvi-tools)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from scib) (0.12.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from scib) (0.56.4)\n",
            "Collecting scikit-misc (from scib)\n",
            "  Downloading scikit_misc-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn (from scib)\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from scib) (1.4.2)\n",
            "Collecting igraph>=0.10 (from scib)\n",
            "  Downloading igraph-0.10.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite in /usr/local/lib/python3.10/dist-packages (from scib) (0.39.1)\n",
            "Collecting deprecated (from scib)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting plottable (from scib_metrics)\n",
            "  Downloading plottable-0.1.5-py3-none-any.whl (24 kB)\n",
            "Collecting pynndescent (from scib_metrics)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.4->scarches) (8.3.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.4->scarches) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from docrep>=0.3.2->scvi-tools) (1.16.0)\n",
            "Collecting texttable>=1.6.2 (from igraph>=0.10->scib)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.4->scvi-tools) (0.1.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.4->scvi-tools) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (2.8.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (1.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (6.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (0.6.0.post1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=3.0->scvi-tools) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.2->scarches) (2022.7.1)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.6.0->scvi-tools)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools) (4.5.0)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools) (2.14.0)\n",
            "Requirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.6.0->scarches) (0.13.5)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.6.0->scarches) (0.5.3)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.6.0->scarches) (3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.6.0->scarches) (1.2.0)\n",
            "Collecting session-info (from scanpy>=1.6.0->scarches)\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->scib) (67.7.2)\n",
            "Collecting newick~=1.0.0 (from scHPL>=1.0.0->scarches)\n",
            "  Downloading newick-1.0.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->scarches) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scarches) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scarches) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scarches) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scarches) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->scarches) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->scarches) (16.0.5)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex->scvi-tools) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex->scvi-tools) (0.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->scib) (1.14.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (1.0.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (0.2.1)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (0.1.36)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->scarches) (4.11.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from muon->scarches) (3.20.3)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from numpyro->scvi-tools) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (3.4)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.0.0->scvi-tools) (0.1.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->scarches) (2.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->scarches) (2.1.2)\n",
            "Requirement already satisfied: cached_property in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.5.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (5.12.0)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.2.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.5.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (1.7.1)\n",
            "Collecting stdlib_list (from session-info->scanpy>=1.6.0->scarches)\n",
            "  Downloading stdlib_list-0.8.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->scarches) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: docrep, ml-collections, umap-learn, pynndescent, session-info\n",
            "  Building wheel for docrep (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docrep: filename=docrep-0.3.2-py3-none-any.whl size=19877 sha256=d9e14fda7e15c83c96f77e9ee05ea6dc2fe1c760ea9325205040a00defe86434\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/64/48/03c38d8d906159eaa210b3c548fdb590eb3e2a4a5745ae2172\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=64d7e087d1395b9e0733eb51fe1ffe3c8724fb56b881540a022d0c0e7b8ace06\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82816 sha256=5f10c134af462bfd805d14fb78c6ae30c1bfef7dc4f986b96d45b2d3651564b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=c04a60db1cd1682d5ee2a1b10bd77da3c5ff15dde9a6f14249914090324fd5d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=41bfe08e97a64e72111555b806667a787c0a0fc98de0e6e97fab92e95c09e688\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n",
            "Successfully built docrep ml-collections umap-learn pynndescent session-info\n",
            "Installing collected packages: texttable, stdlib_list, pyro-api, newick, faiss-gpu, session-info, scikit-misc, multidict, ml-collections, lightning-utilities, igraph, frozenlist, docrep, deprecated, async-timeout, yarl, leidenalg, aiosignal, scvi_colab, pynndescent, plottable, numpyro, anndata, aiohttp, umap-learn, scHPL, mudata, scanpy, scib_metrics, scib, muon, torchmetrics, pytorch-lightning, pyro-ppl, scvi-tools, scarches\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 anndata-0.9.1 async-timeout-4.0.2 deprecated-1.2.14 docrep-0.3.2 faiss-gpu-1.7.2 frozenlist-1.3.3 igraph-0.10.4 leidenalg-0.9.1 lightning-utilities-0.8.0 ml-collections-0.1.1 mudata-0.2.2 multidict-6.0.4 muon-0.1.3 newick-1.0.0 numpyro-0.12.0 plottable-0.1.5 pynndescent-0.5.10 pyro-api-0.1.2 pyro-ppl-1.8.5 pytorch-lightning-1.9.5 scHPL-1.0.2 scanpy-1.9.3 scarches-0.5.9 scib-1.1.3 scib_metrics-0.3.3 scikit-misc-0.2.0 scvi-tools-0.20.3 scvi_colab-0.12.0 session-info-1.0.0 stdlib_list-0.8.0 texttable-1.6.7 torchmetrics-0.11.4 umap-learn-0.5.3 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install scarches scvi-tools scib scib_metrics scvi_colab faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scanpy as sc\n",
        "import torch\n",
        "import scarches as sca\n",
        "import numpy as np\n",
        "import gdown\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMz_GQlkgVrJ",
        "outputId": "214bd140-4c85-4f1a-ffb1-ffd9d2084354"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:In order to use the mouse gastrulation seqFISH datsets, please install squidpy (see https://github.com/scverse/squidpy).\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n",
            "WARNING:root:In order to use sagenet models, please install pytorch geometric (see https://pytorch-geometric.readthedocs.io) and \n",
            " captum (see https://github.com/pytorch/captum).\n",
            "WARNING:root:mvTCR is not installed. To use mvTCR models, please install it first using \"pip install mvtcr\"\n",
            "WARNING:root:multigrate is not installed. To use multigrate models, please install it first using \"pip install multigrate\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ],
      "metadata": {
        "id": "t1MrOQKRez0q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.set_figure_params(frameon=False)\n",
        "sc.set_figure_params(dpi=200)\n",
        "sc.set_figure_params(figsize=(4, 4))\n",
        "torch.set_printoptions(precision=3, sci_mode=False, edgeitems=7)"
      ],
      "metadata": {
        "id": "oLLy4rYSe2cI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Upload"
      ],
      "metadata": {
        "id": "YRRC8ZJ5e39P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n",
        "input = '/gdrive/MyDrive/Colab Notebooks/gut_data/cancer_integration/input_files/All_cells_5000_HVGs.h5ad'\n",
        "adata = sc.read_h5ad(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G2PnOode5c1",
        "outputId": "3c611817-7dc0-4ca1-9011-1db08121f326"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess datasets"
      ],
      "metadata": {
        "id": "gSP7IJe7fagP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adata.obs['dataset'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5ZbqMBfgdtt",
        "outputId": "05e9f665-89fb-4095-c649-dd0435e955d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "healthy    156195\n",
              "cancer      32181\n",
              "Name: dataset, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Healthy_adata = adata[adata.obs['dataset'] == 'healthy', :]\n",
        "Cancer_adata = adata[adata.obs['dataset'] == 'cancer', :]"
      ],
      "metadata": {
        "id": "-cxyuqpZfuqB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create expiMap model and train it on reference dataset"
      ],
      "metadata": {
        "id": "KP2Q9YMWgAj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mask with all ones (assuming all genes are equally important)\n",
        "Healthy_adata.varm['mask'] = np.ones((Healthy_adata.n_vars, 1))"
      ],
      "metadata": {
        "id": "n5JucUyOgAT-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intr_cvae = sca.models.EXPIMAP(\n",
        "    adata = Healthy_adata,\n",
        "    condition_key='Sample_ID',\n",
        "    hidden_layer_sizes=[256, 256, 256],\n",
        "    recon_loss='nb',\n",
        "    mask_key='mask'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFfG4CadgDvg",
        "outputId": "119fd51e-407b-4b1a-f370-bd884f6fb3a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INITIALIZING NEW NETWORK..............\n",
            "Encoder Architecture:\n",
            "\tInput Layer in, out and cond: 5000 256 233\n",
            "\tHidden Layer 1 in/out: 256 256\n",
            "\tHidden Layer 2 in/out: 256 256\n",
            "\tMean/Var Layer in/out: 256 1\n",
            "Decoder Architecture:\n",
            "\tMasked linear layer in, ext_m, ext, cond, out:  1 0 0 233 5000\n",
            "\twith hard mask.\n",
            "Last Decoder layer: softmax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ALPHA = 0.7"
      ],
      "metadata": {
        "id": "B3-Q1Lhegsd_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw_C3aDUgvpo",
        "outputId": "81668800-88de-49dc-cc93-b790a6225cb7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_kwargs = {\n",
        "    \"early_stopping_metric\": \"val_unweighted_loss\", # val_unweighted_loss\n",
        "    \"threshold\": 0,\n",
        "    \"patience\": 50,\n",
        "    \"reduce_lr\": True,\n",
        "    \"lr_patience\": 13,\n",
        "    \"lr_factor\": 0.1,\n",
        "}\n",
        "intr_cvae.train(\n",
        "    n_epochs=200,\n",
        "    alpha_epoch_anneal=100,\n",
        "    alpha=ALPHA,\n",
        "    alpha_kl=0.5,\n",
        "    weight_decay=0.,\n",
        "    early_stopping_kwargs=early_stopping_kwargs,\n",
        "    use_early_stopping=True,\n",
        "    monitor_only_val=False,\n",
        "    seed=2020,\n",
        "    print_stats=True,\n",
        "    use_gpu = True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgDAdfz5g0bF",
        "outputId": "d8bebcb4-f627-493b-c051-d76693d65b73"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing (156195, 5000)\n",
            "Instantiating dataset\n",
            "Init the group lasso proximal operator for the main terms.\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 0.5%  - epoch_loss: 1840.7884237393 - epoch_recon_loss: 1840.7884237393 - epoch_kl_loss: 10.2473825626 - val_loss: 1068.2286346936 - val_recon_loss: 1068.2286346936 - val_kl_loss: 20.1148480275\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 1.0%  - epoch_loss: 1316.2545887340 - epoch_recon_loss: 1316.1368109686 - epoch_kl_loss: 23.5555419627 - val_loss: 1054.2423245790 - val_recon_loss: 1054.1177743380 - val_kl_loss: 24.9105202096\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 1.5%  - epoch_loss: 1289.5180947044 - epoch_recon_loss: 1289.2521563166 - epoch_kl_loss: 26.5936492920 - val_loss: 1049.4211330726 - val_recon_loss: 1049.1540822514 - val_kl_loss: 26.7056393858\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 2.0%  - epoch_loss: 1271.8949562766 - epoch_recon_loss: 1271.4658761319 - epoch_kl_loss: 28.6053227095 - val_loss: 1043.8766279377 - val_recon_loss: 1043.4555443936 - val_kl_loss: 28.0722009628\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 2.5%  - epoch_loss: 1253.5074490634 - epoch_recon_loss: 1252.9149329723 - epoch_kl_loss: 29.6257512422 - val_loss: 1037.2991142898 - val_recon_loss: 1036.7223440702 - val_kl_loss: 28.8385932328\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 3.0%  - epoch_loss: 1241.3120223722 - epoch_recon_loss: 1240.5517140891 - epoch_kl_loss: 30.4123861018 - val_loss: 1036.5272101731 - val_recon_loss: 1035.8311717549 - val_kl_loss: 27.8415450268\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 3.5%  - epoch_loss: 1230.1431931374 - epoch_recon_loss: 1229.2284950950 - epoch_kl_loss: 30.4898621993 - val_loss: 1034.9353847816 - val_recon_loss: 1034.1253391954 - val_kl_loss: 27.0014863561\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 4.0%  - epoch_loss: 1219.4882653254 - epoch_recon_loss: 1218.4246974321 - epoch_kl_loss: 30.3876979724 - val_loss: 1027.5339885774 - val_recon_loss: 1026.5414478740 - val_kl_loss: 28.3582887650\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 4.5%  - epoch_loss: 1207.3609236284 - epoch_recon_loss: 1206.1572025923 - epoch_kl_loss: 30.0930235273 - val_loss: 1026.1032484711 - val_recon_loss: 1024.9707796691 - val_kl_loss: 28.3117776152\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 5.0%  - epoch_loss: 1199.3536285955 - epoch_recon_loss: 1198.0304647550 - epoch_kl_loss: 29.4036314357 - val_loss: 1023.2507429279 - val_recon_loss: 1021.9745323306 - val_kl_loss: 28.3603046136\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 5.5%  - epoch_loss: 1191.6394692161 - epoch_recon_loss: 1190.1994125644 - epoch_kl_loss: 28.8011459957 - val_loss: 1020.6294285508 - val_recon_loss: 1019.3086797996 - val_kl_loss: 26.4148701527\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 6.0%  - epoch_loss: 1181.5541723633 - epoch_recon_loss: 1180.0111513450 - epoch_kl_loss: 28.0549286530 - val_loss: 1015.6436482414 - val_recon_loss: 1014.1965467109 - val_kl_loss: 26.3109648189\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 6.5%  - epoch_loss: 1178.1993016468 - epoch_recon_loss: 1176.5577968528 - epoch_kl_loss: 27.3583993998 - val_loss: 1013.7789216589 - val_recon_loss: 1012.2417157283 - val_kl_loss: 25.6200948778\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 7.0%  - epoch_loss: 1172.4967249645 - epoch_recon_loss: 1170.7535808216 - epoch_kl_loss: 26.8175899852 - val_loss: 1010.6347200988 - val_recon_loss: 1008.9248597192 - val_kl_loss: 26.3055899729\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 7.5%  - epoch_loss: 1164.8026050360 - epoch_recon_loss: 1162.9821447199 - epoch_kl_loss: 26.0065533309 - val_loss: 1008.1999986993 - val_recon_loss: 1006.4852850242 - val_kl_loss: 24.4958765624\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 8.0%  - epoch_loss: 1160.1367775657 - epoch_recon_loss: 1158.2538264604 - epoch_kl_loss: 25.1060208563 - val_loss: 1007.8903713539 - val_recon_loss: 1006.1561124208 - val_kl_loss: 23.1234189643\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 8.5%  - epoch_loss: 1152.8798809814 - epoch_recon_loss: 1150.9279721347 - epoch_kl_loss: 24.3988539019 - val_loss: 1004.8858167304 - val_recon_loss: 1002.9831467926 - val_kl_loss: 23.7834094313\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 9.0%  - epoch_loss: 1151.2282071755 - epoch_recon_loss: 1149.2138184149 - epoch_kl_loss: 23.6986883597 - val_loss: 1003.7015435891 - val_recon_loss: 1001.7572571801 - val_kl_loss: 22.8739520057\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 9.5%  - epoch_loss: 1150.2973482444 - epoch_recon_loss: 1148.2255327814 - epoch_kl_loss: 23.0201610825 - val_loss: 1000.2594589484 - val_recon_loss: 998.2471688693 - val_kl_loss: 22.3587974955\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 10.0%  - epoch_loss: 1142.1756106290 - epoch_recon_loss: 1140.0551284513 - epoch_kl_loss: 22.3208732345 - val_loss: 1001.7144835425 - val_recon_loss: 999.7204769947 - val_kl_loss: 20.9895320173\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 10.5%  - epoch_loss: 1137.9042833363 - epoch_recon_loss: 1135.7426477051 - epoch_kl_loss: 21.6163523865 - val_loss: 999.3118611320 - val_recon_loss: 997.2590647213 - val_kl_loss: 20.5279606366\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 11.0%  - epoch_loss: 1139.0232999490 - epoch_recon_loss: 1136.8480028742 - epoch_kl_loss: 20.7171315609 - val_loss: 996.9251163670 - val_recon_loss: 994.8824928159 - val_kl_loss: 19.4535712727\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 11.5%  - epoch_loss: 1132.0708851207 - epoch_recon_loss: 1129.8869433594 - epoch_kl_loss: 19.8539980836 - val_loss: 996.4817559915 - val_recon_loss: 994.3206832135 - val_kl_loss: 19.6461251681\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 12.0%  - epoch_loss: 1131.5775941606 - epoch_recon_loss: 1129.3833433949 - epoch_kl_loss: 19.0804373351 - val_loss: 995.1655888792 - val_recon_loss: 993.1276450235 - val_kl_loss: 17.7212583823\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 12.5%  - epoch_loss: 1126.0026523659 - epoch_recon_loss: 1123.8135739968 - epoch_kl_loss: 18.2423148190 - val_loss: 994.1840430088 - val_recon_loss: 992.0685619917 - val_kl_loss: 17.6290001635\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 13.0%  - epoch_loss: 1123.8688071511 - epoch_recon_loss: 1121.6611143355 - epoch_kl_loss: 17.6615447599 - val_loss: 992.2749513720 - val_recon_loss: 990.2086116603 - val_kl_loss: 16.5307228370\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 13.5%  - epoch_loss: 1118.5097880415 - epoch_recon_loss: 1116.3018202348 - epoch_kl_loss: 16.9843652968 - val_loss: 992.3609524086 - val_recon_loss: 990.3233632572 - val_kl_loss: 15.6737581941\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 14.0%  - epoch_loss: 1117.7154307417 - epoch_recon_loss: 1115.5038139759 - epoch_kl_loss: 16.3823479401 - val_loss: 991.2314638232 - val_recon_loss: 989.1016220343 - val_kl_loss: 15.7765777932\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 14.5%  - epoch_loss: 1117.8226781672 - epoch_recon_loss: 1115.6112051114 - epoch_kl_loss: 15.7962340719 - val_loss: 991.6254167400 - val_recon_loss: 989.5688481565 - val_kl_loss: 14.6897756936\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 15.0%  - epoch_loss: 1112.1018288907 - epoch_recon_loss: 1109.8766008412 - epoch_kl_loss: 15.3464067719 - val_loss: 990.8836099593 - val_recon_loss: 988.7674235360 - val_kl_loss: 14.5943845921\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 15.5%  - epoch_loss: 1110.5224355247 - epoch_recon_loss: 1108.2997937012 - epoch_kl_loss: 14.8176144140 - val_loss: 987.8090259990 - val_recon_loss: 985.7757748463 - val_kl_loss: 13.5550224195\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 16.0%  - epoch_loss: 1109.5505069802 - epoch_recon_loss: 1107.3349677069 - epoch_kl_loss: 14.2937992157 - val_loss: 989.5149416064 - val_recon_loss: 987.3983599553 - val_kl_loss: 13.6553643649\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 16.5%  - epoch_loss: 1112.2366813521 - epoch_recon_loss: 1110.0151665150 - epoch_kl_loss: 13.8844643324 - val_loss: 987.4368831447 - val_recon_loss: 985.2855479756 - val_kl_loss: 13.4458662799\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 17.0%  - epoch_loss: 1106.6353233754 - epoch_recon_loss: 1104.4051020397 - epoch_kl_loss: 13.5164817264 - val_loss: 986.9182784284 - val_recon_loss: 984.8522038694 - val_kl_loss: 12.5216748832\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 17.5%  - epoch_loss: 1108.3731024170 - epoch_recon_loss: 1106.1474880149 - epoch_kl_loss: 13.0918536750 - val_loss: 987.3000293169 - val_recon_loss: 985.2642742220 - val_kl_loss: 11.9750257867\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 18.0%  - epoch_loss: 1102.4447883745 - epoch_recon_loss: 1100.2116076105 - epoch_kl_loss: 12.7610309870 - val_loss: 986.3517491075 - val_recon_loss: 984.2901786429 - val_kl_loss: 11.7804019099\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 18.5%  - epoch_loss: 1100.7374422385 - epoch_recon_loss: 1098.4974335827 - epoch_kl_loss: 12.4444858430 - val_loss: 984.3194134822 - val_recon_loss: 982.2006400687 - val_kl_loss: 11.7709638252\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 19.0%  - epoch_loss: 1100.9060720548 - epoch_recon_loss: 1098.6645709783 - epoch_kl_loss: 12.1162175421 - val_loss: 984.6397074715 - val_recon_loss: 982.5182655209 - val_kl_loss: 11.4672602200\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 19.5%  - epoch_loss: 1102.1320840177 - epoch_recon_loss: 1099.8859964267 - epoch_kl_loss: 11.8215108091 - val_loss: 984.0132021044 - val_recon_loss: 981.9227545066 - val_kl_loss: 11.0023610709\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 20.0%  - epoch_loss: 1097.4989630127 - epoch_recon_loss: 1095.2507714289 - epoch_kl_loss: 11.5291834875 - val_loss: 984.4408369221 - val_recon_loss: 982.2772341869 - val_kl_loss: 11.0953973239\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 20.5%  - epoch_loss: 1095.5525044389 - epoch_recon_loss: 1093.3040047385 - epoch_kl_loss: 11.2424974416 - val_loss: 982.9663516185 - val_recon_loss: 980.8862439765 - val_kl_loss: 10.4005186753\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 21.0%  - epoch_loss: 1095.7227409224 - epoch_recon_loss: 1093.4608908358 - epoch_kl_loss: 11.0334140084 - val_loss: 983.6454387727 - val_recon_loss: 981.5758156698 - val_kl_loss: 10.0957219718\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 21.5%  - epoch_loss: 1092.7592687988 - epoch_recon_loss: 1090.4961810858 - epoch_kl_loss: 10.7766053980 - val_loss: 980.6427937492 - val_recon_loss: 978.5494254691 - val_kl_loss: 9.9684001891\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 22.0%  - epoch_loss: 1092.6310347678 - epoch_recon_loss: 1090.3646697443 - epoch_kl_loss: 10.5412349857 - val_loss: 981.6983042232 - val_recon_loss: 979.6109634149 - val_kl_loss: 9.7085690029\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 22.5%  - epoch_loss: 1091.4709578081 - epoch_recon_loss: 1089.1981807085 - epoch_kl_loss: 10.3308017835 - val_loss: 980.9193495453 - val_recon_loss: 978.8062574043 - val_kl_loss: 9.6049685947\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 23.0%  - epoch_loss: 1092.1507182728 - epoch_recon_loss: 1089.8690155584 - epoch_kl_loss: 10.1408940740 - val_loss: 981.2191567343 - val_recon_loss: 979.1069025759 - val_kl_loss: 9.3877990754\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 23.5%  - epoch_loss: 1091.4637320779 - epoch_recon_loss: 1089.1681635631 - epoch_kl_loss: 9.9807299813 - val_loss: 980.2308829886 - val_recon_loss: 978.1343233703 - val_kl_loss: 9.1154742944\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 24.0%  - epoch_loss: 1088.7037053888 - epoch_recon_loss: 1086.4037093284 - epoch_kl_loss: 9.7872126748 - val_loss: 980.3892552110 - val_recon_loss: 978.2268376585 - val_kl_loss: 9.2017778569\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 24.5%  - epoch_loss: 1087.1675904985 - epoch_recon_loss: 1084.8594348699 - epoch_kl_loss: 9.6173138471 - val_loss: 980.0189964420 - val_recon_loss: 977.7891650591 - val_kl_loss: 9.2909518539\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 25.0%  - epoch_loss: 1087.6224023992 - epoch_recon_loss: 1085.3016004528 - epoch_kl_loss: 9.4726585128 - val_loss: 981.0706161749 - val_recon_loss: 978.8917411429 - val_kl_loss: 8.8933690493\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 25.5%  - epoch_loss: 1085.0263554798 - epoch_recon_loss: 1082.6965845836 - epoch_kl_loss: 9.3190892488 - val_loss: 978.2085436211 - val_recon_loss: 975.9789693864 - val_kl_loss: 8.9183034819\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 26.0%  - epoch_loss: 1084.1705952037 - epoch_recon_loss: 1081.8291853471 - epoch_kl_loss: 9.1819908411 - val_loss: 978.2162230445 - val_recon_loss: 976.0745159212 - val_kl_loss: 8.3988484945\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 26.5%  - epoch_loss: 1082.5530943714 - epoch_recon_loss: 1080.2046698553 - epoch_kl_loss: 9.0324020628 - val_loss: 977.8674051254 - val_recon_loss: 975.6731062092 - val_kl_loss: 8.4396231761\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 27.0%  - epoch_loss: 1082.4380417148 - epoch_recon_loss: 1080.0779079368 - epoch_kl_loss: 8.9061704792 - val_loss: 979.6040689437 - val_recon_loss: 977.3928427774 - val_kl_loss: 8.3442408609\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 27.5%  - epoch_loss: 1082.4670321933 - epoch_recon_loss: 1080.1009902122 - epoch_kl_loss: 8.7631181205 - val_loss: 977.4188937828 - val_recon_loss: 975.2619969102 - val_kl_loss: 7.9885220723\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 28.0%  - epoch_loss: 1079.1117661355 - epoch_recon_loss: 1076.7477990168 - epoch_kl_loss: 8.5962449152 - val_loss: 977.1011227467 - val_recon_loss: 974.8838961242 - val_kl_loss: 8.0626463890\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 28.5%  - epoch_loss: 1082.7437051114 - epoch_recon_loss: 1080.3720862371 - epoch_kl_loss: 8.4700663770 - val_loss: 977.2820729740 - val_recon_loss: 975.1200016209 - val_kl_loss: 7.7216654879\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 29.0%  - epoch_loss: 1080.4416357977 - epoch_recon_loss: 1078.0716553289 - epoch_kl_loss: 8.3157235653 - val_loss: 977.4713514985 - val_recon_loss: 975.2837394339 - val_kl_loss: 7.6758265183\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 29.5%  - epoch_loss: 1080.0549166038 - epoch_recon_loss: 1077.6811597235 - epoch_kl_loss: 8.1853719672 - val_loss: 975.9608344406 - val_recon_loss: 973.7515623999 - val_kl_loss: 7.6181713519\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 30.0%  - epoch_loss: 1076.4786727628 - epoch_recon_loss: 1074.0927481357 - epoch_kl_loss: 8.0878817736 - val_loss: 976.3128872230 - val_recon_loss: 974.0590305016 - val_kl_loss: 7.6401996065\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 30.5%  - epoch_loss: 1077.4608779075 - epoch_recon_loss: 1075.0733387895 - epoch_kl_loss: 7.9584643225 - val_loss: 975.5922526375 - val_recon_loss: 973.4067292761 - val_kl_loss: 7.2850805541\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 31.0%  - epoch_loss: 1076.3342595881 - epoch_recon_loss: 1073.9367058216 - epoch_kl_loss: 7.8608305411 - val_loss: 975.9948115114 - val_recon_loss: 973.7869757981 - val_kl_loss: 7.2388047781\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 31.5%  - epoch_loss: 1074.5028636586 - epoch_recon_loss: 1072.1042868874 - epoch_kl_loss: 7.7373464853 - val_loss: 974.5817640961 - val_recon_loss: 972.3801314557 - val_kl_loss: 7.1020464819\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 32.0%  - epoch_loss: 1072.4451556951 - epoch_recon_loss: 1070.0333687522 - epoch_kl_loss: 7.6564649396 - val_loss: 975.0242464660 - val_recon_loss: 972.7719171243 - val_kl_loss: 7.1502484884\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 32.5%  - epoch_loss: 1071.6044321511 - epoch_recon_loss: 1069.1797167414 - epoch_kl_loss: 7.5772347116 - val_loss: 973.9644935483 - val_recon_loss: 971.7089563589 - val_kl_loss: 7.0485560660\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 33.0%  - epoch_loss: 1073.3521847812 - epoch_recon_loss: 1070.9254074929 - epoch_kl_loss: 7.4670059486 - val_loss: 975.7700885710 - val_recon_loss: 973.4867623751 - val_kl_loss: 7.0256180490\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 33.5%  - epoch_loss: 1070.6102744363 - epoch_recon_loss: 1068.1670280318 - epoch_kl_loss: 7.4037807746 - val_loss: 973.8813231421 - val_recon_loss: 971.5734558105 - val_kl_loss: 6.9935451375\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 34.0%  - epoch_loss: 1070.5915612793 - epoch_recon_loss: 1068.1441860130 - epoch_kl_loss: 7.3055975966 - val_loss: 974.6098257596 - val_recon_loss: 972.3228944872 - val_kl_loss: 6.8266647487\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 34.5%  - epoch_loss: 1072.8904321844 - epoch_recon_loss: 1070.4327667236 - epoch_kl_loss: 7.2284219412 - val_loss: 974.1628873231 - val_recon_loss: 971.9418940310 - val_kl_loss: 6.5323283438\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 35.0%  - epoch_loss: 1071.2211949019 - epoch_recon_loss: 1068.7565488503 - epoch_kl_loss: 7.1439015818 - val_loss: 973.4171202613 - val_recon_loss: 971.1483134285 - val_kl_loss: 6.5762565214\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 35.5%  - epoch_loss: 1070.7725208074 - epoch_recon_loss: 1068.2926524214 - epoch_kl_loss: 7.0853371122 - val_loss: 972.6585283123 - val_recon_loss: 970.3594805608 - val_kl_loss: 6.5687130553\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 36.0%  - epoch_loss: 1070.8754740767 - epoch_recon_loss: 1068.3872817161 - epoch_kl_loss: 7.0089926069 - val_loss: 971.9825249344 - val_recon_loss: 969.6463252834 - val_kl_loss: 6.5808476229\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 36.5%  - epoch_loss: 1069.3009427157 - epoch_recon_loss: 1066.8026389937 - epoch_kl_loss: 6.9397333930 - val_loss: 973.9403951676 - val_recon_loss: 971.6022909196 - val_kl_loss: 6.4947316490\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 37.0%  - epoch_loss: 1067.4625650302 - epoch_recon_loss: 1064.9502448065 - epoch_kl_loss: 6.8830726173 - val_loss: 972.9672336266 - val_recon_loss: 970.6203378146 - val_kl_loss: 6.4298629174\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 37.5%  - epoch_loss: 1066.6617025479 - epoch_recon_loss: 1064.1356934149 - epoch_kl_loss: 6.8270492909 - val_loss: 972.7645253666 - val_recon_loss: 970.4662880819 - val_kl_loss: 6.2114624586\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 38.0%  - epoch_loss: 1065.6957064542 - epoch_recon_loss: 1063.1620667614 - epoch_kl_loss: 6.7563708379 - val_loss: 972.3546552814 - val_recon_loss: 970.0074172723 - val_kl_loss: 6.2593051840\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 38.5%  - epoch_loss: 1066.1194144509 - epoch_recon_loss: 1063.5692245761 - epoch_kl_loss: 6.7110286067 - val_loss: 971.2608467477 - val_recon_loss: 968.9350856093 - val_kl_loss: 6.1204272372\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 39.0%  - epoch_loss: 1064.8600540439 - epoch_recon_loss: 1062.3009466553 - epoch_kl_loss: 6.6470314932 - val_loss: 972.5895605869 - val_recon_loss: 970.1912086362 - val_kl_loss: 6.2294827446\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 39.5%  - epoch_loss: 1065.9809135298 - epoch_recon_loss: 1063.4093491433 - epoch_kl_loss: 6.5937523348 - val_loss: 971.7969245285 - val_recon_loss: 969.4412266465 - val_kl_loss: 6.0402597208\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 40.0%  - epoch_loss: 1063.4453718706 - epoch_recon_loss: 1060.8601059792 - epoch_kl_loss: 6.5449809785 - val_loss: 971.8805411917 - val_recon_loss: 969.4572944016 - val_kl_loss: 6.1348047061\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 40.5%  - epoch_loss: 1061.9418406539 - epoch_recon_loss: 1059.3466178755 - epoch_kl_loss: 6.4880616838 - val_loss: 971.0994727963 - val_recon_loss: 968.7418593110 - val_kl_loss: 5.8940421870\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 41.0%  - epoch_loss: 1067.3448128995 - epoch_recon_loss: 1064.7349865168 - epoch_kl_loss: 6.4440185751 - val_loss: 970.5251144659 - val_recon_loss: 968.0900323586 - val_kl_loss: 6.0125458983\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 41.5%  - epoch_loss: 1063.9660394287 - epoch_recon_loss: 1061.3440608354 - epoch_kl_loss: 6.3950734888 - val_loss: 971.8975785052 - val_recon_loss: 969.5035510454 - val_kl_loss: 5.8390903082\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 42.0%  - epoch_loss: 1061.9987869540 - epoch_recon_loss: 1059.3676696777 - epoch_kl_loss: 6.3400390885 - val_loss: 971.6858335401 - val_recon_loss: 969.3072990042 - val_kl_loss: 5.7314068489\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 42.5%  - epoch_loss: 1063.4563939875 - epoch_recon_loss: 1060.8098003041 - epoch_kl_loss: 6.3014151244 - val_loss: 969.8382798492 - val_recon_loss: 967.4202985920 - val_kl_loss: 5.7570993236\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 43.0%  - epoch_loss: 1061.8015646085 - epoch_recon_loss: 1059.1446540416 - epoch_kl_loss: 6.2515558555 - val_loss: 970.4055160773 - val_recon_loss: 967.9969732566 - val_kl_loss: 5.6671593150\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 43.5%  - epoch_loss: 1063.4839997448 - epoch_recon_loss: 1060.8088481001 - epoch_kl_loss: 6.2212826525 - val_loss: 969.6789020476 - val_recon_loss: 967.2027077597 - val_kl_loss: 5.7585935436\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 44.0%  - epoch_loss: 1062.5876112504 - epoch_recon_loss: 1059.9012580455 - epoch_kl_loss: 6.1755264022 - val_loss: 971.8853639696 - val_recon_loss: 969.3752216277 - val_kl_loss: 5.7704370843\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 44.5%  - epoch_loss: 1060.8667358953 - epoch_recon_loss: 1058.1673890270 - epoch_kl_loss: 6.1348816390 - val_loss: 970.5119408779 - val_recon_loss: 968.0985392586 - val_kl_loss: 5.4850074033\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 45.0%  - epoch_loss: 1060.7268017023 - epoch_recon_loss: 1058.0157933461 - epoch_kl_loss: 6.0921489867 - val_loss: 969.9398128322 - val_recon_loss: 967.4552572282 - val_kl_loss: 5.5832703074\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 45.5%  - epoch_loss: 1060.8902430309 - epoch_recon_loss: 1058.1661239901 - epoch_kl_loss: 6.0536031207 - val_loss: 970.2798591989 - val_recon_loss: 967.8241216941 - val_kl_loss: 5.4571954188\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 46.0%  - epoch_loss: 1061.2274380771 - epoch_recon_loss: 1058.4922148548 - epoch_kl_loss: 6.0114794909 - val_loss: 969.6005259029 - val_recon_loss: 967.1219132220 - val_kl_loss: 5.4475040788\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 46.5%  - epoch_loss: 1060.9597162420 - epoch_recon_loss: 1058.2030158580 - epoch_kl_loss: 5.9928289912 - val_loss: 970.0533387231 - val_recon_loss: 967.4805512975 - val_kl_loss: 5.5930130247\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 47.0%  - epoch_loss: 1057.5342578680 - epoch_recon_loss: 1054.7679675293 - epoch_kl_loss: 5.9490081011 - val_loss: 967.6724493308 - val_recon_loss: 965.1804809570 - val_kl_loss: 5.3590691950\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 47.5%  - epoch_loss: 1060.9597925360 - epoch_recon_loss: 1058.1744310414 - epoch_kl_loss: 5.9263056291 - val_loss: 968.8327071393 - val_recon_loss: 966.2839855757 - val_kl_loss: 5.4228113636\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 48.0%  - epoch_loss: 1056.9630638539 - epoch_recon_loss: 1054.1672118031 - epoch_kl_loss: 5.8860057441 - val_loss: 968.1942083640 - val_recon_loss: 965.6885531066 - val_kl_loss: 5.2750642378\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 48.5%  - epoch_loss: 1059.1098578436 - epoch_recon_loss: 1056.3042926580 - epoch_kl_loss: 5.8449303142 - val_loss: 968.7110935899 - val_recon_loss: 966.1606740483 - val_kl_loss: 5.3133821057\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 49.0%  - epoch_loss: 1058.8447988614 - epoch_recon_loss: 1056.0228193803 - epoch_kl_loss: 5.8185118935 - val_loss: 966.7054258253 - val_recon_loss: 964.1398900767 - val_kl_loss: 5.2897627275\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 49.5%  - epoch_loss: 1057.7591904519 - epoch_recon_loss: 1054.9269728227 - epoch_kl_loss: 5.7800373004 - val_loss: 967.9719268299 - val_recon_loss: 965.3901277136 - val_kl_loss: 5.2689818515\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 50.0%  - epoch_loss: 1056.6751330012 - epoch_recon_loss: 1053.8284108110 - epoch_kl_loss: 5.7509523327 - val_loss: 968.0714046291 - val_recon_loss: 965.5032523734 - val_kl_loss: 5.1881838783\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 50.5%  - epoch_loss: 1055.7035574063 - epoch_recon_loss: 1052.8466140470 - epoch_kl_loss: 5.7138855379 - val_loss: 967.6853137407 - val_recon_loss: 965.0909093638 - val_kl_loss: 5.1888085350\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 51.0%  - epoch_loss: 1054.8564474765 - epoch_recon_loss: 1052.0090374201 - epoch_kl_loss: 5.6948222559 - val_loss: 968.1577328541 - val_recon_loss: 965.5619636911 - val_kl_loss: 5.1915407493\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 51.5%  - epoch_loss: 1055.8933771307 - epoch_recon_loss: 1053.0529756858 - epoch_kl_loss: 5.6808019482 - val_loss: 966.9368161061 - val_recon_loss: 964.3634943728 - val_kl_loss: 5.1466421651\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 52.0%  - epoch_loss: 1055.4595214289 - epoch_recon_loss: 1052.6323668879 - epoch_kl_loss: 5.6543103686 - val_loss: 967.3539778913 - val_recon_loss: 964.7226632540 - val_kl_loss: 5.2626323426\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 52.5%  - epoch_loss: 1056.4323967396 - epoch_recon_loss: 1053.6132734819 - epoch_kl_loss: 5.6382431481 - val_loss: 966.6506067495 - val_recon_loss: 964.0963164783 - val_kl_loss: 5.1085892075\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 53.0%  - epoch_loss: 1052.9285742188 - epoch_recon_loss: 1050.1203827459 - epoch_kl_loss: 5.6163867877 - val_loss: 966.4484403016 - val_recon_loss: 963.8673570977 - val_kl_loss: 5.1621698473\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 53.5%  - epoch_loss: 1052.4117105935 - epoch_recon_loss: 1049.6142223011 - epoch_kl_loss: 5.5949788427 - val_loss: 966.1494525847 - val_recon_loss: 963.5742622751 - val_kl_loss: 5.1503833122\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 54.0%  - epoch_loss: 1054.8721788996 - epoch_recon_loss: 1052.0806044145 - epoch_kl_loss: 5.5831500058 - val_loss: 966.6069090796 - val_recon_loss: 964.0491323002 - val_kl_loss: 5.1155573345\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 54.5%  - epoch_loss: 1055.7453353050 - epoch_recon_loss: 1052.9675227495 - epoch_kl_loss: 5.5556300618 - val_loss: 966.9812226843 - val_recon_loss: 964.4300597144 - val_kl_loss: 5.1023310286\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 55.0%  - epoch_loss: 1052.3015662176 - epoch_recon_loss: 1049.5303641579 - epoch_kl_loss: 5.5424023433 - val_loss: 966.9212806577 - val_recon_loss: 964.3789102523 - val_kl_loss: 5.0847347838\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 55.5%  - epoch_loss: 1052.5200503263 - epoch_recon_loss: 1049.7583396773 - epoch_kl_loss: 5.5234210868 - val_loss: 965.6472223000 - val_recon_loss: 963.1280157371 - val_kl_loss: 5.0384095653\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 56.0%  - epoch_loss: 1054.6791076660 - epoch_recon_loss: 1051.9203844105 - epoch_kl_loss: 5.5174437722 - val_loss: 965.9791850106 - val_recon_loss: 963.4391639584 - val_kl_loss: 5.0800390517\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 56.5%  - epoch_loss: 1053.5956490257 - epoch_recon_loss: 1050.8478899037 - epoch_kl_loss: 5.4955190893 - val_loss: 965.5817465860 - val_recon_loss: 963.1173355853 - val_kl_loss: 4.9288219155\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 57.0%  - epoch_loss: 1051.3723176159 - epoch_recon_loss: 1048.6321449973 - epoch_kl_loss: 5.4803446280 - val_loss: 964.5656092910 - val_recon_loss: 962.0438567615 - val_kl_loss: 5.0434992978\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 57.5%  - epoch_loss: 1050.5161244895 - epoch_recon_loss: 1047.7812200373 - epoch_kl_loss: 5.4698067145 - val_loss: 967.3045904441 - val_recon_loss: 964.8216437668 - val_kl_loss: 4.9658943512\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 58.0%  - epoch_loss: 1050.3750067694 - epoch_recon_loss: 1047.6480391069 - epoch_kl_loss: 5.4539360996 - val_loss: 965.8617908916 - val_recon_loss: 963.3938918817 - val_kl_loss: 4.9357976210\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 58.5%  - epoch_loss: 1048.1347510875 - epoch_recon_loss: 1045.4142932129 - epoch_kl_loss: 5.4409121262 - val_loss: 965.9105509774 - val_recon_loss: 963.3984119853 - val_kl_loss: 5.0242817675\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 59.0%  - epoch_loss: 1049.2575459428 - epoch_recon_loss: 1046.5385960804 - epoch_kl_loss: 5.4378974763 - val_loss: 965.6029072746 - val_recon_loss: 963.0843265721 - val_kl_loss: 5.0371558627\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 59.5%  - epoch_loss: 1050.2050027743 - epoch_recon_loss: 1047.4924097235 - epoch_kl_loss: 5.4251855928 - val_loss: 964.8103917857 - val_recon_loss: 962.3044193455 - val_kl_loss: 5.0119520406\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 60.0%  - epoch_loss: 1054.2527794855 - epoch_recon_loss: 1051.5457285933 - epoch_kl_loss: 5.4141036450 - val_loss: 966.6094105205 - val_recon_loss: 964.1520946065 - val_kl_loss: 4.9146324650\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 60.5%  - epoch_loss: 1052.1082145552 - epoch_recon_loss: 1049.4033692516 - epoch_kl_loss: 5.4096897598 - val_loss: 964.3994095599 - val_recon_loss: 961.9180192791 - val_kl_loss: 4.9627772355\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 61.0%  - epoch_loss: 1051.0076222923 - epoch_recon_loss: 1048.3078611617 - epoch_kl_loss: 5.3995253537 - val_loss: 964.7127225282 - val_recon_loss: 962.2274495109 - val_kl_loss: 4.9705495834\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 61.5%  - epoch_loss: 1049.0361123935 - epoch_recon_loss: 1046.3457704301 - epoch_kl_loss: 5.3806832665 - val_loss: 963.9397853163 - val_recon_loss: 961.5248668233 - val_kl_loss: 4.8298358214\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 62.0%  - epoch_loss: 1049.8742690763 - epoch_recon_loss: 1047.1887278609 - epoch_kl_loss: 5.3710829861 - val_loss: 964.4445170418 - val_recon_loss: 962.0413993460 - val_kl_loss: 4.8062347819\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 62.5%  - epoch_loss: 1051.0298475231 - epoch_recon_loss: 1048.3443159069 - epoch_kl_loss: 5.3710658880 - val_loss: 965.2747677662 - val_recon_loss: 962.8197196585 - val_kl_loss: 4.9100892309\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 63.0%  - epoch_loss: 1049.2849624911 - epoch_recon_loss: 1046.6092200262 - epoch_kl_loss: 5.3514817502 - val_loss: 964.5541281778 - val_recon_loss: 962.0884754619 - val_kl_loss: 4.9313049434\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 63.5%  - epoch_loss: 1044.3575836737 - epoch_recon_loss: 1041.6833963845 - epoch_kl_loss: 5.3483762217 - val_loss: 964.1674069264 - val_recon_loss: 961.7311041160 - val_kl_loss: 4.8726036041\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 64.0%  - epoch_loss: 1050.0501830500 - epoch_recon_loss: 1047.3794138406 - epoch_kl_loss: 5.3415390413 - val_loss: 964.0554234239 - val_recon_loss: 961.5670246062 - val_kl_loss: 4.9768022592\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 64.5%  - epoch_loss: 1049.0452327659 - epoch_recon_loss: 1046.3760770486 - epoch_kl_loss: 5.3383106149 - val_loss: 964.4367885902 - val_recon_loss: 962.0016169314 - val_kl_loss: 4.8703414339\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 65.0%  - epoch_loss: 1048.7553713157 - epoch_recon_loss: 1046.0916937256 - epoch_kl_loss: 5.3273569692 - val_loss: 965.1904727123 - val_recon_loss: 962.7734940326 - val_kl_loss: 4.8339572265\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 65.5%  - epoch_loss: 1046.4214137407 - epoch_recon_loss: 1043.7614202326 - epoch_kl_loss: 5.3199863109 - val_loss: 963.1796574827 - val_recon_loss: 960.7663694288 - val_kl_loss: 4.8265770263\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 66.0%  - epoch_loss: 1046.7071707431 - epoch_recon_loss: 1044.0476947576 - epoch_kl_loss: 5.3189532887 - val_loss: 962.0713490971 - val_recon_loss: 959.6528820601 - val_kl_loss: 4.8369300326\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 66.5%  - epoch_loss: 1049.6192340088 - epoch_recon_loss: 1046.9691099964 - epoch_kl_loss: 5.3002477672 - val_loss: 962.7462323298 - val_recon_loss: 960.3025622759 - val_kl_loss: 4.8873344797\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 67.0%  - epoch_loss: 1047.4837066096 - epoch_recon_loss: 1044.8298089600 - epoch_kl_loss: 5.3077951362 - val_loss: 961.3248571177 - val_recon_loss: 958.9354102963 - val_kl_loss: 4.7788974262\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 67.5%  - epoch_loss: 1047.7830556419 - epoch_recon_loss: 1045.1398708274 - epoch_kl_loss: 5.2863683219 - val_loss: 961.9599724441 - val_recon_loss: 959.5287320497 - val_kl_loss: 4.8624854010\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 68.0%  - epoch_loss: 1047.9508513849 - epoch_recon_loss: 1045.3117542614 - epoch_kl_loss: 5.2781966313 - val_loss: 962.0029672091 - val_recon_loss: 959.6206860151 - val_kl_loss: 4.7645594644\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 68.5%  - epoch_loss: 1042.0583192583 - epoch_recon_loss: 1039.4169678289 - epoch_kl_loss: 5.2827048618 - val_loss: 964.6226856669 - val_recon_loss: 962.2140758077 - val_kl_loss: 4.8172148447\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 69.0%  - epoch_loss: 1045.0727207808 - epoch_recon_loss: 1042.4357325328 - epoch_kl_loss: 5.2739789837 - val_loss: 963.6983712618 - val_recon_loss: 961.3014986632 - val_kl_loss: 4.7937421603\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 69.5%  - epoch_loss: 1045.9119024658 - epoch_recon_loss: 1043.2804132080 - epoch_kl_loss: 5.2629758419 - val_loss: 963.0303264680 - val_recon_loss: 960.6504681697 - val_kl_loss: 4.7597171596\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 70.0%  - epoch_loss: 1043.2075092662 - epoch_recon_loss: 1040.5791991078 - epoch_kl_loss: 5.2566174286 - val_loss: 963.7386519635 - val_recon_loss: 961.2961390761 - val_kl_loss: 4.8850293668\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 70.5%  - epoch_loss: 1043.3891934482 - epoch_recon_loss: 1040.7621796764 - epoch_kl_loss: 5.2540270818 - val_loss: 961.5772284836 - val_recon_loss: 959.1935399790 - val_kl_loss: 4.7673751604\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 71.0%  - epoch_loss: 1046.5035268333 - epoch_recon_loss: 1043.8777191162 - epoch_kl_loss: 5.2516165040 - val_loss: 961.4494223673 - val_recon_loss: 959.0667359399 - val_kl_loss: 4.7653701696\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 71.5%  - epoch_loss: 1045.4465962913 - epoch_recon_loss: 1042.8196511563 - epoch_kl_loss: 5.2538924048 - val_loss: 961.5774376041 - val_recon_loss: 959.2081844142 - val_kl_loss: 4.7385094244\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 72.0%  - epoch_loss: 1043.3229899458 - epoch_recon_loss: 1040.7036255438 - epoch_kl_loss: 5.2387295211 - val_loss: 962.5718648942 - val_recon_loss: 960.1360753794 - val_kl_loss: 4.8715858108\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 72.5%  - epoch_loss: 1043.2864795477 - epoch_recon_loss: 1040.6767186390 - epoch_kl_loss: 5.2195222556 - val_loss: 962.3277983118 - val_recon_loss: 959.9899797283 - val_kl_loss: 4.6756410677\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 73.0%  - epoch_loss: 1044.9410931951 - epoch_recon_loss: 1042.3263156405 - epoch_kl_loss: 5.2295581254 - val_loss: 962.2424951772 - val_recon_loss: 959.8363802550 - val_kl_loss: 4.8122372119\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 73.5%  - epoch_loss: 1042.2800556530 - epoch_recon_loss: 1039.6652991278 - epoch_kl_loss: 5.2295117565 - val_loss: 962.4980503770 - val_recon_loss: 960.0837502401 - val_kl_loss: 4.8286037328\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 74.0%  - epoch_loss: 1046.2108047208 - epoch_recon_loss: 1043.5966113281 - epoch_kl_loss: 5.2283862322 - val_loss: 961.1531747286 - val_recon_loss: 958.7629769747 - val_kl_loss: 4.7803897037\n",
            "ADJUSTED LR\n",
            "\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 74.5%  - epoch_loss: 1040.1224629905 - epoch_recon_loss: 1037.5137820157 - epoch_kl_loss: 5.2173626106 - val_loss: 960.9282166528 - val_recon_loss: 958.5442840076 - val_kl_loss: 4.7678620464\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 75.0%  - epoch_loss: 1043.7583884499 - epoch_recon_loss: 1041.1530051491 - epoch_kl_loss: 5.2107672691 - val_loss: 961.3972658251 - val_recon_loss: 959.0282522733 - val_kl_loss: 4.7380288155\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 75.5%  - epoch_loss: 1040.1949993896 - epoch_recon_loss: 1037.5845985551 - epoch_kl_loss: 5.2208002207 - val_loss: 960.5342357198 - val_recon_loss: 958.1496707103 - val_kl_loss: 4.7691360575\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 76.0%  - epoch_loss: 1044.1916008967 - epoch_recon_loss: 1041.5865767600 - epoch_kl_loss: 5.2100497493 - val_loss: 961.1684945529 - val_recon_loss: 958.7854649278 - val_kl_loss: 4.7660602116\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 76.5%  - epoch_loss: 1044.3597359397 - epoch_recon_loss: 1041.7513051536 - epoch_kl_loss: 5.2168618298 - val_loss: 960.2769670330 - val_recon_loss: 957.8752021164 - val_kl_loss: 4.8035252290\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 77.0%  - epoch_loss: 1042.9316922829 - epoch_recon_loss: 1040.3247202925 - epoch_kl_loss: 5.2139465796 - val_loss: 961.0761503626 - val_recon_loss: 958.6885826236 - val_kl_loss: 4.7751392067\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 77.5%  - epoch_loss: 1039.9789233398 - epoch_recon_loss: 1037.3719683838 - epoch_kl_loss: 5.2139089073 - val_loss: 962.0842490274 - val_recon_loss: 959.7172081119 - val_kl_loss: 4.7340777311\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 78.0%  - epoch_loss: 1043.0328258722 - epoch_recon_loss: 1040.4268860973 - epoch_kl_loss: 5.2118791866 - val_loss: 960.2988581423 - val_recon_loss: 957.9279164799 - val_kl_loss: 4.7418816324\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 78.5%  - epoch_loss: 1044.2910932506 - epoch_recon_loss: 1041.6850260787 - epoch_kl_loss: 5.2121369730 - val_loss: 961.0273467517 - val_recon_loss: 958.6589265417 - val_kl_loss: 4.7368440198\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 79.0%  - epoch_loss: 1040.4005120850 - epoch_recon_loss: 1037.7957225453 - epoch_kl_loss: 5.2095788726 - val_loss: 961.2389416304 - val_recon_loss: 958.8608953757 - val_kl_loss: 4.7560908912\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 79.5%  - epoch_loss: 1041.1641160445 - epoch_recon_loss: 1038.5590691029 - epoch_kl_loss: 5.2100940232 - val_loss: 960.1479161997 - val_recon_loss: 957.7702741779 - val_kl_loss: 4.7552834456\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 80.0%  - epoch_loss: 1043.7588624157 - epoch_recon_loss: 1041.1503083385 - epoch_kl_loss: 5.2171112503 - val_loss: 960.3418594110 - val_recon_loss: 957.9585946505 - val_kl_loss: 4.7665331833\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 80.5%  - epoch_loss: 1041.8564279452 - epoch_recon_loss: 1039.2526072554 - epoch_kl_loss: 5.2076416254 - val_loss: 960.6398200363 - val_recon_loss: 958.2633406842 - val_kl_loss: 4.7529608773\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 81.0%  - epoch_loss: 1042.0865854159 - epoch_recon_loss: 1039.4877673895 - epoch_kl_loss: 5.1976335248 - val_loss: 960.4925487081 - val_recon_loss: 958.1108683602 - val_kl_loss: 4.7633637678\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 81.5%  - epoch_loss: 1042.4830301736 - epoch_recon_loss: 1039.8796381170 - epoch_kl_loss: 5.2067875676 - val_loss: 961.9515610992 - val_recon_loss: 959.5789569792 - val_kl_loss: 4.7452062505\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 82.0%  - epoch_loss: 1042.9521194181 - epoch_recon_loss: 1040.3526303933 - epoch_kl_loss: 5.1989779368 - val_loss: 960.8036238874 - val_recon_loss: 958.4224803487 - val_kl_loss: 4.7622878317\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 82.5%  - epoch_loss: 1041.1227925803 - epoch_recon_loss: 1038.5207465709 - epoch_kl_loss: 5.2040932218 - val_loss: 961.8322818944 - val_recon_loss: 959.4521234231 - val_kl_loss: 4.7603191313\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 83.0%  - epoch_loss: 1040.9954548784 - epoch_recon_loss: 1038.3913896595 - epoch_kl_loss: 5.2081301641 - val_loss: 960.0207734655 - val_recon_loss: 957.6379609655 - val_kl_loss: 4.7656300654\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 83.5%  - epoch_loss: 1039.9154004461 - epoch_recon_loss: 1037.3105959251 - epoch_kl_loss: 5.2096125646 - val_loss: 961.0901339171 - val_recon_loss: 958.7178409764 - val_kl_loss: 4.7445830126\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 84.0%  - epoch_loss: 1043.3172056441 - epoch_recon_loss: 1040.7149101673 - epoch_kl_loss: 5.2045936017 - val_loss: 961.2381766898 - val_recon_loss: 958.8640506932 - val_kl_loss: 4.7482524426\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 84.5%  - epoch_loss: 1041.6153703169 - epoch_recon_loss: 1039.0112546054 - epoch_kl_loss: 5.2082321284 - val_loss: 960.8058191518 - val_recon_loss: 958.4258552926 - val_kl_loss: 4.7599252560\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 85.0%  - epoch_loss: 1042.0488942649 - epoch_recon_loss: 1039.4417896063 - epoch_kl_loss: 5.2142126859 - val_loss: 961.1830909604 - val_recon_loss: 958.8019854436 - val_kl_loss: 4.7622126595\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 85.5%  - epoch_loss: 1039.3618874290 - epoch_recon_loss: 1036.7539565763 - epoch_kl_loss: 5.2158627657 - val_loss: 960.8382308210 - val_recon_loss: 958.4639377281 - val_kl_loss: 4.7485922204\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 86.0%  - epoch_loss: 1046.1734178578 - epoch_recon_loss: 1043.5713633034 - epoch_kl_loss: 5.2041092894 - val_loss: 959.7294001345 - val_recon_loss: 957.3590703245 - val_kl_loss: 4.7406548555\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 86.5%  - epoch_loss: 1045.1723613392 - epoch_recon_loss: 1042.5696003307 - epoch_kl_loss: 5.2055217054 - val_loss: 960.7568929704 - val_recon_loss: 958.3780277440 - val_kl_loss: 4.7577310507\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 87.0%  - epoch_loss: 1045.0811036266 - epoch_recon_loss: 1042.4765688809 - epoch_kl_loss: 5.2090698957 - val_loss: 960.5179133181 - val_recon_loss: 958.1499178527 - val_kl_loss: 4.7359920877\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 87.5%  - epoch_loss: 1041.2663499867 - epoch_recon_loss: 1038.6633580988 - epoch_kl_loss: 5.2059846947 - val_loss: 960.3353996902 - val_recon_loss: 957.9515445897 - val_kl_loss: 4.7677147037\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 88.0%  - epoch_loss: 1043.1783785733 - epoch_recon_loss: 1040.5773946311 - epoch_kl_loss: 5.2019688212 - val_loss: 961.0228706735 - val_recon_loss: 958.6335194072 - val_kl_loss: 4.7786966386\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 88.5%  - epoch_loss: 1044.7383890048 - epoch_recon_loss: 1042.1362491122 - epoch_kl_loss: 5.2042812113 - val_loss: 961.8225527904 - val_recon_loss: 959.4585651335 - val_kl_loss: 4.7279772094\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 89.0%  - epoch_loss: 1040.8556344882 - epoch_recon_loss: 1038.2556679466 - epoch_kl_loss: 5.1999343859 - val_loss: 960.3099285188 - val_recon_loss: 957.9491357022 - val_kl_loss: 4.7215846327\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 89.5%  - epoch_loss: 1041.9013087602 - epoch_recon_loss: 1039.3008051647 - epoch_kl_loss: 5.2010039568 - val_loss: 960.9806818728 - val_recon_loss: 958.6036306913 - val_kl_loss: 4.7540937017\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 90.0%  - epoch_loss: 1041.0253549472 - epoch_recon_loss: 1038.4234634122 - epoch_kl_loss: 5.2037847606 - val_loss: 961.2140542953 - val_recon_loss: 958.8350234735 - val_kl_loss: 4.7580580047\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 90.5%  - epoch_loss: 1039.5110405939 - epoch_recon_loss: 1036.9101883212 - epoch_kl_loss: 5.2017041436 - val_loss: 959.8779782155 - val_recon_loss: 957.5076143859 - val_kl_loss: 4.7407263654\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 91.0%  - epoch_loss: 1040.3041006192 - epoch_recon_loss: 1037.7100354004 - epoch_kl_loss: 5.1881305690 - val_loss: 959.7466825892 - val_recon_loss: 957.3773163342 - val_kl_loss: 4.7387293519\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 91.5%  - epoch_loss: 1044.0443135210 - epoch_recon_loss: 1041.4411157781 - epoch_kl_loss: 5.2063954774 - val_loss: 961.4754858799 - val_recon_loss: 959.1008080654 - val_kl_loss: 4.7493612923\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 92.0%  - epoch_loss: 1039.5291440097 - epoch_recon_loss: 1036.9298914684 - epoch_kl_loss: 5.1985075907 - val_loss: 959.7092805456 - val_recon_loss: 957.3405191390 - val_kl_loss: 4.7375257758\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 92.5%  - epoch_loss: 1044.2614857622 - epoch_recon_loss: 1041.6593120783 - epoch_kl_loss: 5.2043490956 - val_loss: 959.5008364818 - val_recon_loss: 957.1219522445 - val_kl_loss: 4.7577670207\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 93.0%  - epoch_loss: 1040.0198960738 - epoch_recon_loss: 1037.4205993097 - epoch_kl_loss: 5.1985931067 - val_loss: 959.9159085633 - val_recon_loss: 957.5380629242 - val_kl_loss: 4.7556884523\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 93.5%  - epoch_loss: 1043.4121839489 - epoch_recon_loss: 1040.8156860906 - epoch_kl_loss: 5.1929969532 - val_loss: 959.9352351955 - val_recon_loss: 957.5724072066 - val_kl_loss: 4.7256562202\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 94.0%  - epoch_loss: 1043.1765312611 - epoch_recon_loss: 1040.5787748580 - epoch_kl_loss: 5.1955102192 - val_loss: 960.4129893819 - val_recon_loss: 958.0393646741 - val_kl_loss: 4.7472503850\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 94.5%  - epoch_loss: 1046.3126192960 - epoch_recon_loss: 1043.7127626731 - epoch_kl_loss: 5.1997131738 - val_loss: 960.8853439581 - val_recon_loss: 958.5273812716 - val_kl_loss: 4.7159210971\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 95.0%  - epoch_loss: 1042.8857204368 - epoch_recon_loss: 1040.2862814608 - epoch_kl_loss: 5.1988778756 - val_loss: 959.8199978187 - val_recon_loss: 957.4546833976 - val_kl_loss: 4.7306343141\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 95.5%  - epoch_loss: 1039.9096519886 - epoch_recon_loss: 1037.3141726407 - epoch_kl_loss: 5.1909595260 - val_loss: 959.3203089980 - val_recon_loss: 956.9515911165 - val_kl_loss: 4.7374376313\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 96.0%  - epoch_loss: 1040.2935789906 - epoch_recon_loss: 1037.6943464799 - epoch_kl_loss: 5.1984691299 - val_loss: 960.1301194488 - val_recon_loss: 957.7635047788 - val_kl_loss: 4.7332297505\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 96.5%  - epoch_loss: 1038.9499364680 - epoch_recon_loss: 1036.3510353782 - epoch_kl_loss: 5.1978067875 - val_loss: 959.7242041416 - val_recon_loss: 957.3586095591 - val_kl_loss: 4.7311881409\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 97.0%  - epoch_loss: 1043.0327407005 - epoch_recon_loss: 1040.4318740567 - epoch_kl_loss: 5.2017320928 - val_loss: 960.4544997919 - val_recon_loss: 958.0868275126 - val_kl_loss: 4.7353434289\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 97.5%  - epoch_loss: 1040.0949976141 - epoch_recon_loss: 1037.4943574663 - epoch_kl_loss: 5.2012786900 - val_loss: 961.0967742420 - val_recon_loss: 958.7387520212 - val_kl_loss: 4.7160459425\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 98.0%  - epoch_loss: 1039.3718914240 - epoch_recon_loss: 1036.7726836048 - epoch_kl_loss: 5.1984175327 - val_loss: 960.7450556521 - val_recon_loss: 958.3709366595 - val_kl_loss: 4.7482338772\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 98.5%  - epoch_loss: 1039.1380808882 - epoch_recon_loss: 1036.5403351940 - epoch_kl_loss: 5.1954910278 - val_loss: 961.0877080198 - val_recon_loss: 958.7210093014 - val_kl_loss: 4.7333954280\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 99.0%  - epoch_loss: 1042.0096127042 - epoch_recon_loss: 1039.4142316229 - epoch_kl_loss: 5.1907612541 - val_loss: 959.4792090244 - val_recon_loss: 957.1116728235 - val_kl_loss: 4.7350750048\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 99.5%  - epoch_loss: 1040.7780020419 - epoch_recon_loss: 1038.1843372137 - epoch_kl_loss: 5.1873297063 - val_loss: 960.5520784972 - val_recon_loss: 958.1856649430 - val_kl_loss: 4.7328236533\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████████| 100.0%  - epoch_loss: 1039.9807477362 - epoch_recon_loss: 1037.3845533336 - epoch_kl_loss: 5.1923897635 - val_loss: 959.4770287686 - val_recon_loss: 957.1015795098 - val_kl_loss: 4.7509018202\n",
            "Saving best state of network...\n",
            "Best State was in Epoch 190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MEAN = False"
      ],
      "metadata": {
        "id": "HiiezszMhhc2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Healthy_adata.obsm['X_cvae'] = intr_cvae.get_latent(mean=MEAN, only_active=True)"
      ],
      "metadata": {
        "id": "gqTGWQGxhi03"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.pp.neighbors(Healthy_adata, use_rep='X_cvae')"
      ],
      "metadata": {
        "id": "9pjz94ShiT-r"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initlizling the model for query training"
      ],
      "metadata": {
        "id": "wjiUUJxhiWYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_intr_cvae = sca.models.EXPIMAP.load_query_data(Cancer_adata, intr_cvae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOudCAziiX0g",
        "outputId": "f7c8cbbb-1d45-488c-bcdc-c7e5c9800dc5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View of AnnData object with n_obs × n_vars = 32181 × 5000\n",
            "    obs: 'Sample_ID', 'Cell Type', 'Study_name', 'Donor_ID', 'Diagnosis', 'Age', 'Region code', 'Fraction', 'Gender', 'Library_Preparation_Protocol', 'batch', 'Age_group', 'Location', 'Cell States', 'Cell States GCA', 'Chem', 'Layer', 'Cell States Kong', 'dataset', 'n_genes_by_counts', 'total_counts', 'total_counts_mito', 'pct_counts_mito', 'total_counts_ribo', 'pct_counts_ribo', 'Cell_ID', '_scvi_batch', '_scvi_labels', 'Unified Cell States', 'nFeature_RNA', 'dataset_x', 'iCMS', 'msi', 'dataset_y', 'Tumor Stage', 'MSS/MSI', 'Side', 'Group Stage', 'Stage TNM', 'iCMS.transcriptomic', 'iCMS.inferCNV', 'KRAS', 'BRAF', 'TP53', 'APC', 'PIK3CA', 'LymphNode', 'Normal', 'Tumor', 'CMS'\n",
            "    var: 'feature_types-cancer', 'genome-cancer', 'n_cells_by_counts-cancer', 'mean_counts-cancer', 'log1p_mean_counts-cancer', 'pct_dropout_by_counts-cancer', 'total_counts-cancer', 'log1p_total_counts-cancer', 'gene_id-Kong-healthy', 'gene_name-Kong-healthy', 'n_cells_by_counts-Kong-healthy', 'mean_counts-Kong-healthy', 'log1p_mean_counts-Kong-healthy', 'pct_dropout_by_counts-Kong-healthy', 'total_counts-Kong-healthy', 'log1p_total_counts-Kong-healthy', 'mito-Kong-healthy', 'ribo-Kong-healthy', 'highly_variable-Kong-healthy', 'highly_variable_rank-Kong-healthy', 'means-Kong-healthy', 'variances-Kong-healthy', 'variances_norm-Kong-healthy', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm', 'highly_variable_nbatches'\n",
            "    uns: 'hvg'\n",
            "    layers: 'counts'\n",
            "\n",
            "INITIALIZING NEW NETWORK..............\n",
            "Encoder Architecture:\n",
            "\tInput Layer in, out and cond: 5000 256 330\n",
            "\tHidden Layer 1 in/out: 256 256\n",
            "\tHidden Layer 2 in/out: 256 256\n",
            "\tMean/Var Layer in/out: 256 1\n",
            "Decoder Architecture:\n",
            "\tMasked linear layer in, ext_m, ext, cond, out:  1 0 0 330 5000\n",
            "\twith hard mask.\n",
            "Last Decoder layer: softmax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_intr_cvae.train(n_epochs=200, alpha_epoch_anneal=100, weight_decay=0., alpha_kl=0.1, seed=2020, use_early_stopping=True, print_stats=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "740iP86ZiiDc",
        "outputId": "d2adfacd-0402-47f3-f0c5-b1f021cc6ccd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing (32181, 5000)\n",
            "Instantiating dataset\n",
            " |████████████████████| 100.0%  - val_loss: 1317.5009619141 - val_recon_loss: 1317.0665136719 - val_kl_loss: 4.3444687271\n",
            "Saving best state of network...\n",
            "Best State was in Epoch 198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Cancer_adata.obsm['X_cvae'] = q_intr_cvae.get_latent(mean=MEAN, only_active=True)"
      ],
      "metadata": {
        "id": "mbBZ4MGNikPB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adata = sc.AnnData.concatenate(Healthy_adata, Cancer_adata, batch_key='batch_join', uns_merge='same')"
      ],
      "metadata": {
        "id": "lOuSpwt7jY0C"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "q_intr_cvae.save('/content/gdrive/MyDrive/Colab Notebooks/gut_data/cancer_integration/output_files/cancer_model')\n",
        "\n",
        "adata.write('/content/gdrive/MyDrive/Colab Notebooks/gut_data/cancer_integration/output_files/Epithelial_healthy_and_Joanito_cancer_integrated_andata.h5ad')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcgKZ4hGi1DW",
        "outputId": "3a9ed226-6997-4a02-f14c-ea499cb01eba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    }
  ]
}